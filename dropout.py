# -*- coding: utf-8 -*-
"""Dropout

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1unvoIacXn8IliDzt1D7Jy4S2eW-Dpnxq
"""

#desgargamos mlflow
!pip install mlflow --quiet
#Agregamos esto para poder usar mlflow mas conectar con Dagshub
REPO_NAME = "Regularizadores"
USER_NAME = "javimesa16"
#ya descargado importamos mlflow y aparte os
import mlflow
import os
from getpass import getpass
#agregramos la autentificacion con dagshub y el tracking
os.environ['MLFLOW_TRACKING_USERNAME'] = USER_NAME
os.environ['MLFLOW_TRACKING_PASSWORD'] = getpass('Introduce tu token de DAGsHub: ')
mlflow.set_tracking_uri(f'https://dagshub.com/javimesa16/Regularizadores.mlflow')
#importamos las liberiaras que usaremos de tensorflow
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
#la funcion de activacion sigue siendo la sigmoide
from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input
from tensorflow.keras.optimizers import SGD #importamos el SGD
#importamos mnist ahora sin necesidad de descargarla en la computadora
from tensorflow.keras.datasets import mnist
#importamos los regularizadores
from tensorflow.keras import regularizers
import numpy as np
import matplotlib.pyplot as plt #esta para poder graficar
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback # Import the missing classes

#Definimos los paramentros a usar mismos de la network de la tarea 3
learning_rate = 0.001
momentum = 0.9
epochs = 30
batch_size = 10
num_classes = 10

# Cargamos los datos de Mnist tanto de entrenamiento como de prueba
(x_train, y_train), (x_test, y_test) = mnist.load_data()
#convertimos las imagenes en un vector de 784 entradas y normalizamos entre 0 y 1
x_train = x_train.reshape(-1, 784).astype("float32") / 255.0
x_test = x_test.reshape(-1, 784).astype("float32") / 255.0

# One-hot encoding para nombrar a cada digito entre 0 y 9 como un vector
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)

#iniciamos con una secuancial
model = Sequential()
model.add(Dense(100, activation='sigmoid', input_shape=(784,)))
#implementacion del dropout
model.add(Dropout(0.5))
#saldra en una capa de 10 neuronas pero cambiamos la sigmoide por softmax
model.add(Dense(num_classes, activation='softmax'))

#agregamos el autolog de mlflow
mlflow.tensorflow.autolog()
#en esta parte hacemos que guarde el mejor modelo
#y si despues de 15 epocas no mejora devuelve el mejor archivo guardado
filepath = "best_model.keras"
checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1,
                              save_best_only=True, mode='min')
earlystop = EarlyStopping(monitor='val_loss', mode='min',
                           restore_best_weights=True, patience=15, verbose=1)
#aqui hacemos que despues de cada epoca se ejecute y registre todas las metricas
#por cada epoca y las suba al repositorio de DagsHub
class MlflowLogger(Callback):
    def on_epoch_end(self, epoch, logs=None):
        logs = logs or {}
        #sube las metricas o las actualiza mejor dicho
        for key, value in logs.items():
            mlflow.log_metric(key, value, step=epoch)

        # Cada 5 epocas genera una grafica de c vs epochs y las sube
        if (epoch + 1) % 5 == 0:
            plt.plot(self.model.history.history['loss'], label="Entrenamiento")
            plt.plot(self.model.history.history['val_loss'], label="Validación")
            plt.xlabel("Epochs")
            plt.ylabel("Loss")
            plt.title("Costo vs Epochs")
            plt.legend()
            plot_path = f"loss_curve_epoch{epoch+1}.png"
            plt.savefig(plot_path)
            mlflow.log_artifact(plot_path)
            plt.close()

#para evitar problemas cone le experimento
experiment_name = "Dropout" #lo nombramos a nuestro gusto
#verifica si hay un archivo con ese nombre
try:
    experiment = mlflow.get_experiment_by_name(experiment_name)
    experiment_id = experiment.experiment_id
except:
    #si no existe lo crea y ahi se subiran las metricas
    experiment_id = mlflow.create_experiment(experiment_name)
#todo se registra en ese nombre
with mlflow.start_run(experiment_id=experiment_id, run_name="Dropout"):
    # definimos la funcion de costo binary usamos el optimizador momento
    #asi mismo las metricas de como va todo dado por accuracy
    optimizer = SGD(learning_rate=learning_rate, momentum=momentum)
    model.compile(loss="categorical_crossentropy", optimizer=optimizer, metrics=["accuracy"])

    #el entranamiento tendra esta forma
    #se entrena a la red con los datos usando las epicas
    #se guarda la informacion en history
    history = model.fit(
        x_train, y_train,
        batch_size=batch_size,
        epochs=epochs,
        validation_data=(x_test, y_test),
        verbose=1,
        callbacks=[checkpoint, earlystop, MlflowLogger()] # Add callbacks here
    )

    # se evalua el modelo
    score = model.evaluate(x_test, y_test, verbose=1)
    #imprima el costo del entrenamiento y la precicion con la que le atina
    print(f"Test loss: {score[0]:.4f}")
    print(f"Test accuracy: {score[1]:.4f}")

    # Con esto generamos la grafica de costos vs epochs de el test y entrenamiento
    plt.plot(history.history['loss'], label="Entrenamiento")
    plt.plot(history.history['val_loss'], label="Validación")
    plt.xlabel("Epochs")
    plt.ylabel("Loss")
    plt.title("Costo vs Epochs")
    plt.legend()
    plt.show()